{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Transform tokens into features\n",
    "1 - Bag Of Words\n",
    "\n",
    "# lets count occurences of a particular token in our text\n",
    ". Motivation: We are looking for marker words like \"excellent\" or \"disappointed\"\n",
    ". For each token we will have feature columns,this is called text vectorization\n",
    "\n",
    "# Problems-\n",
    ". We loose word order hence called Bag Of Words\n",
    ". Counters are not normalized.\n",
    "\n",
    "2-Preserve Some Ordering\n",
    ". We can count token pairs,triplet etc.\n",
    ". Also known as n-grams\n",
    " - 1-gram for tokens\n",
    " - 2-grams for token pairs\n",
    " \n",
    " # Problems-\n",
    "  Too many features.\n",
    " \n",
    "# To overcome a problem of too many features we can remove some n-Grams\n",
    ". Lets remove some n-grams from features based on their occurence frequency in documents of corpus.\n",
    "\n",
    "# High Frequency n-grams\n",
    ". Articles prepositions etc( Example: a,and,the)\n",
    ". They are called stop words they wont help us to descriminate texts -> remove them.\n",
    "\n",
    "# Low Frequency n-grams\n",
    ". Typos rare n-grams.\n",
    ". We dont need them either,otherwise we will likely overfit.\n",
    "\n",
    "# Medium Frequency n-grams\n",
    ". Those are good n-grams.\n",
    "\n",
    "\n",
    "# There are lot of medium frequency n-grams\n",
    ". It proved to be useful to look at n-gram frequency in our corpus \n",
    "  for filtering out bad n-grams\n",
    ". What if we use it for rannking of medium frequency n-grams?\n",
    ". Idea:the n-gram with smaller frequency can be more decriminating because it can capture a specific issue in the review\n",
    "\n",
    "#TF-IDF\n",
    "* TERM FREQUENCY(TF)-\n",
    ". tf(t,d)- frequency of term (or n-gram) t in document d\n",
    "\n",
    "\n",
    "* Inverse Document Frequency(IDF)\n",
    ". N = |D|-total number of documents in corpus\n",
    ".|{d E D: t E d}|- number of documents where the term t appears\n",
    ".idf(t,D)=log(N/|{d E D: t E d}|)\n",
    "    here,\n",
    "    E-stands for epsilon\n",
    "    \n",
    " # TF-IDF\n",
    " . tfidf(t,d,D)=tf(t,d).idf(t,D)\n",
    " . A high weight in TF-IDF is reached by high term frequency(in the given document) and alow document     frequency of the term in the whole collection of document\n",
    " \n",
    " # Better BOW\n",
    " . Replace counters with TF-IDF\n",
    " . Normalize the result row-wise(divide by L2-norm)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good movie</th>\n",
       "      <th>like</th>\n",
       "      <th>movie</th>\n",
       "      <th>not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   good movie      like     movie       not\n",
       "0    0.707107  0.000000  0.707107  0.000000\n",
       "1    0.577350  0.000000  0.577350  0.577350\n",
       "2    0.000000  0.707107  0.000000  0.707107\n",
       "3    0.000000  1.000000  0.000000  0.000000\n",
       "4    0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Python TF-IDF example\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "texts=[\"good movie\",\"not a good movie\",\"did not like\",\"i like it\",\n",
    "      \"good one\"]\n",
    "tfidf=TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))\n",
    "features=tfidf.fit_transform(texts)\n",
    "pd.DataFrame(features.todense(),\n",
    "            columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
